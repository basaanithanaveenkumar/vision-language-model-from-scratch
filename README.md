# vlm-multi_token_prediction
Multi-token prediction in Vision-Language Models (VLMs) is an advanced training and inference technique that enables models to predict multiple future tokens simultaneously, rather than one token at a time. This approach has emerged as a promising area for improving efficiency, model performance, and inference speed.
